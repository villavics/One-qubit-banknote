{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "468623c8",
   "metadata": {},
   "source": [
    "# Banknote Authentication – 1-Qubit QML vs Classical Models (ES, λ=24, 60 gens)\n",
    "\n",
    "Esta libreta implementa el experimento de autenticación de billetes con:\n",
    "\n",
    "- Un clasificador cuántico de **1 qubit** entrenado con *Evolution Strategies* (ES).\n",
    "- Modelos clásicos de referencia: Regresión Logística y MLP.\n",
    "\n",
    "Hiperparámetros principales del QML:\n",
    "\n",
    "- $\\mu = 5$ padres  \n",
    "- $\\lambda = 24$ hijos por generación  \n",
    "- $\\alpha = 0.1$ (escala del ruido)  \n",
    "- 60 generaciones  \n",
    "- Hasta 600 muestras de entrenamiento para el QML  \n",
    "- 256 *shots* por evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8e1202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Imports and basic config ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# SpinQit / SpinQ\n",
    "try:\n",
    "    from spinqkit import get_basic_simulator, get_compiler, Circuit, Rx, Ry, Rz, BasicSimulatorConfig\n",
    "except ImportError:\n",
    "    try:\n",
    "        from spinqkit import get_basic_simulator, get_compiler, Circuit, Rx, Ry, Rz\n",
    "        from spinqkit.backends import BasicSimulatorConfig\n",
    "    except ImportError as e:\n",
    "        raise ImportError(\n",
    "            \"No pude importar BasicSimulatorConfig desde spinqkit. \"\n",
    "            \"Verifica la instalación / versión de SpinQit.\"\n",
    "        ) from e\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"Imports OK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d3462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Load and preprocess Banknote dataset ===\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Carga el dataset Banknote desde archivo local o desde UCI.\"\"\"\n",
    "    import numpy as _np\n",
    "    try:\n",
    "        data = _np.loadtxt(\"data_banknote_authentication.txt\",\n",
    "                           delimiter=\",\", dtype=_np.float64)\n",
    "    except Exception:\n",
    "        import urllib.request\n",
    "        url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\"\n",
    "        print(\"Descargando datos desde UCI...\")\n",
    "        urllib.request.urlretrieve(url, \"data_banknote_authentication.txt\")\n",
    "        data = _np.loadtxt(\"data_banknote_authentication.txt\",\n",
    "                           delimiter=\",\", dtype=_np.float64)\n",
    "    return data\n",
    "\n",
    "data = load_data()\n",
    "x_raw = data[:, :-1]\n",
    "y = data[:, -1].astype(int)\n",
    "\n",
    "print(\"Raw shape:\", x_raw.shape, \"labels shape:\", y.shape)\n",
    "\n",
    "# Escalado columna a columna a [0, pi]\n",
    "x_scaled = x_raw.copy()\n",
    "for col in range(x_scaled.shape[1]):\n",
    "    mini, maxi = np.min(x_scaled[:, col]), np.max(x_scaled[:, col])\n",
    "    x_scaled[:, col] = np.pi * (x_scaled[:, col] - mini) / (maxi - mini)\n",
    "\n",
    "# Features 2D: x1 = sqrt(var+skew), x2 = sqrt(curtosis)\n",
    "x2d = np.empty((x_scaled.shape[0], 2), dtype=np.float32)\n",
    "x2d[:, 0] = np.sqrt(x_scaled[:, 0] + x_scaled[:, 1])\n",
    "x2d[:, 1] = np.sqrt(x_scaled[:, 2])\n",
    "\n",
    "print(\"2D features shape:\", x2d.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x2d, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Test: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d2940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2b. Scatter plot of feature space (Fig. 8 style) ===\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "mask0 = (y == 0)\n",
    "mask1 = (y == 1)\n",
    "plt.scatter(x2d[mask0, 0], x2d[mask0, 1], c='red', s=20, label='Class 0')\n",
    "plt.scatter(x2d[mask1, 0], x2d[mask1, 1], c='blue', s=20, label='Class 1')\n",
    "plt.xlabel(r\"$\\sqrt{\\mathrm{variance} + \\mathrm{skewness}}$\")\n",
    "plt.ylabel(\"Curtosis\")\n",
    "plt.title(\"Decision space of the BNA dataset\\n(after feature extraction and selection)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210e31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. One-qubit Quantum Classifier with ES (lambda=24, 60 gens) ===\n",
    "\n",
    "class QuantumClassifier:\n",
    "    \"\"\"Modelo QML de 1 qubit con 3 parámetros.\"\"\"\n",
    "    def __init__(self, n_params=3, shots=256):\n",
    "        self.n_params = n_params\n",
    "        self.shots = shots\n",
    "        self.params = np.zeros(n_params, dtype=np.float64)\n",
    "        self.engine = get_basic_simulator()\n",
    "        self.compiler = get_compiler(\"native\")\n",
    "\n",
    "    def circuit(self, x, params):\n",
    "        x = np.asarray(x, dtype=np.float64).flatten()\n",
    "        params = np.asarray(params, dtype=np.float64).flatten()\n",
    "        if x.size != 2:\n",
    "            raise ValueError(f\"x must be 2D, got {x.shape}\")\n",
    "        if params.size != 3:\n",
    "            raise ValueError(f\"params must have length 3, got {params.shape}\")\n",
    "\n",
    "        circ = Circuit()\n",
    "        q = circ.allocateQubits(1)\n",
    "\n",
    "        # Codificación de datos\n",
    "        circ << (Ry, q[0], float(x[1]))\n",
    "        circ << (Rz, q[0], float(x[0]))\n",
    "\n",
    "        # Capa variacional\n",
    "        circ << (Rx, q[0], float(params[0]))\n",
    "        circ << (Rz, q[0], float(params[1]))\n",
    "        circ << (Ry, q[0], float(params[2]))\n",
    "\n",
    "        return circ\n",
    "\n",
    "    def _run_and_prob1(self, x, params):\n",
    "        circ = self.circuit(x, params)\n",
    "        exe = self.compiler.compile(circ, 0)\n",
    "\n",
    "        config = BasicSimulatorConfig()\n",
    "        config.configure_shots(self.shots)\n",
    "\n",
    "        result = self.engine.execute(exe, config)\n",
    "        counts = result.counts\n",
    "        total = sum(counts.values())\n",
    "        if total == 0:\n",
    "            return 0.5\n",
    "        p1 = counts.get('1', 0) / total\n",
    "        p1 = float(np.clip(p1, 1e-7, 1 - 1e-7))\n",
    "        return p1\n",
    "\n",
    "    def predict_proba(self, X, params=None):\n",
    "        if params is None:\n",
    "            params = self.params\n",
    "        X = np.atleast_2d(X)\n",
    "        probs = np.zeros(X.shape[0], dtype=np.float64)\n",
    "        for i, x in enumerate(X):\n",
    "            probs[i] = self._run_and_prob1(x, params)\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X, params=None, threshold=0.5):\n",
    "        p = self.predict_proba(X, params)\n",
    "        return (p > threshold).astype(int)\n",
    "\n",
    "    def accuracy(self, params, X, y):\n",
    "        y = np.asarray(y, dtype=int)\n",
    "        y_pred = self.predict(X, params=params)\n",
    "        return accuracy_score(y, y_pred)\n",
    "\n",
    "    def fit_es_fast(self, X, y, mu=5, lam=24, alpha=0.1, iters=60,\n",
    "                    max_train_samples=600, seed=None, verbose=True):\n",
    "        \"\"\"Entrenamiento ES.\n",
    "\n",
    "        - mu=5 padres, lam=24 hijos\n",
    "        - iters=60 generaciones\n",
    "        - max_train_samples: máximo de muestras para acelerar el QML\n",
    "        \"\"\"\n",
    "        X = np.asarray(X, dtype=np.float64)\n",
    "        y = np.asarray(y, dtype=int)\n",
    "\n",
    "        rng = np.random.default_rng(seed)\n",
    "\n",
    "        # Submuestreo para acelerar\n",
    "        if max_train_samples is not None and X.shape[0] > max_train_samples:\n",
    "            idx = rng.choice(X.shape[0], size=max_train_samples, replace=False)\n",
    "            X = X[idx]\n",
    "            y = y[idx]\n",
    "\n",
    "        # Inicializar padres\n",
    "        parents = rng.uniform(-np.pi/4, np.pi/4, size=(mu, self.n_params))\n",
    "        acc_parents = np.array([self.accuracy(p, X, y) for p in parents])\n",
    "        best_idx = int(np.argmax(acc_parents))\n",
    "        best_params = parents[best_idx].copy()\n",
    "        best_acc = float(acc_parents[best_idx])\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[ES] Init best accuracy = {best_acc:.4f}\")\n",
    "\n",
    "        for gen in range(iters):\n",
    "            children = np.zeros((lam, self.n_params), dtype=np.float64)\n",
    "            for j in range(lam):\n",
    "                parent_idx = rng.integers(mu)\n",
    "                noise = alpha * rng.normal(0.0, 1.0, size=self.n_params)\n",
    "                children[j] = parents[parent_idx] + noise\n",
    "\n",
    "            acc_children = np.array([self.accuracy(ch, X, y) for ch in children])\n",
    "            idx_sorted = np.argsort(-acc_children)\n",
    "            parents = children[idx_sorted[:mu]]\n",
    "            acc_parents = acc_children[idx_sorted[:mu]]\n",
    "\n",
    "            if acc_parents[0] > best_acc:\n",
    "                best_acc = float(acc_parents[0])\n",
    "                best_params = parents[0].copy()\n",
    "\n",
    "            if verbose and (gen % 10 == 0 or gen == iters-1):\n",
    "                print(f\"[ES] Gen {gen+1:2d}/{iters}: best_acc={best_acc:.4f}\")\n",
    "\n",
    "        self.params = best_params\n",
    "        if verbose:\n",
    "            print(f\"[ES] Finished. Best accuracy = {best_acc:.4f}\")\n",
    "        return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149317b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. Single-run experiment ===\n",
    "\n",
    "def run_single_experiment(random_state=0, verbose=True):\n",
    "    X_tr, X_ts, y_tr, y_ts = train_test_split(\n",
    "        x2d, y, test_size=0.2, stratify=y, random_state=random_state\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[Run {random_state}] Train {X_tr.shape}, Test {X_ts.shape}\")\n",
    "\n",
    "    # QML con ES (mu=5, lam=24, iters=60)\n",
    "    qml = QuantumClassifier(n_params=3, shots=256)\n",
    "    qml.fit_es_fast(X_tr, y_tr,\n",
    "                    mu=5, lam=24, alpha=0.1, iters=60,\n",
    "                    max_train_samples=600,\n",
    "                    seed=random_state, verbose=False)\n",
    "    y_tr_q = qml.predict(X_tr)\n",
    "    y_ts_q = qml.predict(X_ts)\n",
    "    acc_tr_q = accuracy_score(y_tr, y_tr_q)\n",
    "    acc_ts_q = accuracy_score(y_ts, y_ts_q)\n",
    "\n",
    "    # Regresión logística\n",
    "    lr = LogisticRegression(max_iter=500, random_state=random_state)\n",
    "    lr.fit(X_tr, y_tr)\n",
    "    y_tr_lr = lr.predict(X_tr)\n",
    "    y_ts_lr = lr.predict(X_ts)\n",
    "    acc_tr_lr = accuracy_score(y_tr, y_tr_lr)\n",
    "    acc_ts_lr = accuracy_score(y_ts, y_ts_lr)\n",
    "\n",
    "    # MLP (clásico)\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(50, 50),\n",
    "                        activation='relu',\n",
    "                        solver='adam',\n",
    "                        learning_rate_init=0.001,\n",
    "                        max_iter=300,\n",
    "                        random_state=random_state)\n",
    "    mlp.fit(X_tr, y_tr)\n",
    "    y_tr_mlp = mlp.predict(X_tr)\n",
    "    y_ts_mlp = mlp.predict(X_ts)\n",
    "    acc_tr_mlp = accuracy_score(y_tr, y_tr_mlp)\n",
    "    acc_ts_mlp = accuracy_score(y_ts, y_ts_mlp)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"  QML train/test: {acc_tr_q:.4f} / {acc_ts_q:.4f}\")\n",
    "        print(f\"  LR  train/test: {acc_tr_lr:.4f} / {acc_ts_lr:.4f}\")\n",
    "        print(f\"  MLP train/test: {acc_tr_mlp:.4f} / {acc_ts_mlp:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"X_tr\": X_tr, \"y_tr\": y_tr,\n",
    "        \"X_ts\": X_ts, \"y_ts\": y_ts,\n",
    "        \"qml\": qml, \"lr\": lr, \"mlp\": mlp,\n",
    "        \"acc_tr_q\": acc_tr_q, \"acc_ts_q\": acc_ts_q,\n",
    "        \"acc_tr_lr\": acc_tr_lr, \"acc_ts_lr\": acc_ts_lr,\n",
    "        \"acc_tr_mlp\": acc_tr_mlp, \"acc_ts_mlp\": acc_ts_mlp,\n",
    "        \"seed\": random_state\n",
    "    }\n",
    "\n",
    "print(\"Quick sanity check (1 run)...\")\n",
    "res0 = run_single_experiment(random_state=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3916eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5. 10 runs: statistics summary ===\n",
    "\n",
    "n_runs = 10\n",
    "all_runs = []\n",
    "\n",
    "for seed in range(n_runs):\n",
    "    print(f\"\\n=== Run {seed+1}/{n_runs} (seed={seed}) ===\")\n",
    "    r = run_single_experiment(random_state=seed, verbose=False)\n",
    "    print(f\"QML train/test: {r['acc_tr_q']:.4f} / {r['acc_ts_q']:.4f}\")\n",
    "    print(f\"LR  train/test: {r['acc_tr_lr']:.4f} / {r['acc_ts_lr']:.4f}\")\n",
    "    print(f\"MLP train/test: {r['acc_tr_mlp']:.4f} / {r['acc_ts_mlp']:.4f}\")\n",
    "    all_runs.append(r)\n",
    "\n",
    "records = []\n",
    "for r in all_runs:\n",
    "    records.append({\n",
    "        \"seed\": r[\"seed\"],\n",
    "        \"train_qml\": r[\"acc_tr_q\"],\n",
    "        \"test_qml\":  r[\"acc_ts_q\"],\n",
    "        \"train_lr\":  r[\"acc_tr_lr\"],\n",
    "        \"test_lr\":   r[\"acc_ts_lr\"],\n",
    "        \"train_mlp\": r[\"acc_tr_mlp\"],\n",
    "        \"test_mlp\":  r[\"acc_ts_mlp\"],\n",
    "    })\n",
    "\n",
    "runs_df = pd.DataFrame(records)\n",
    "display(runs_df.head())\n",
    "\n",
    "def mean_std(col):\n",
    "    return runs_df[col].mean()*100, runs_df[col].std()*100\n",
    "\n",
    "summary = {\n",
    "    \"Model\": [\"QML (1 qubit, ES λ=24, 60 gens)\", \"Logistic Regression\", \"MLP (50, 50)\"],\n",
    "    \"Train Acc (mean ± std) [%]\": [\n",
    "        f\"{mean_std('train_qml')[0]:.2f} ± {mean_std('train_qml')[1]:.2f}\",\n",
    "        f\"{mean_std('train_lr')[0]:.2f}  ± {mean_std('train_lr')[1]:.2f}\",\n",
    "        f\"{mean_std('train_mlp')[0]:.2f} ± {mean_std('train_mlp')[1]:.2f}\",\n",
    "    ],\n",
    "    \"Test Acc (mean ± std) [%]\": [\n",
    "        f\"{mean_std('test_qml')[0]:.2f} ± {mean_std('test_qml')[1]:.2f}\",\n",
    "        f\"{mean_std('test_lr')[0]:.2f}  ± {mean_std('test_lr')[1]:.2f}\",\n",
    "        f\"{mean_std('test_mlp')[0]:.2f} ± {mean_std('test_mlp')[1]:.2f}\",\n",
    "    ],\n",
    "    \"Best train/test [%]\": [\n",
    "        f\"{runs_df['train_qml'].max()*100:.2f} / {runs_df['test_qml'].max()*100:.2f}\",\n",
    "        f\"{runs_df['train_lr'].max()*100:.2f}  / {runs_df['test_lr'].max()*100:.2f}\",\n",
    "        f\"{runs_df['train_mlp'].max()*100:.2f} / {runs_df['test_mlp'].max()*100:.2f}\",\n",
    "    ],\n",
    "    \"Parameters (approx)\": [3, 3, 2751],\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(\"\\nSummary over 10 runs:\")\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6. Decision boundaries for best QML run ===\n",
    "\n",
    "best_idx = runs_df['test_qml'].idxmax()\n",
    "best_run = all_runs[best_idx]\n",
    "print(\"Best QML run seed:\", best_run[\"seed\"])\n",
    "\n",
    "X_tr = best_run[\"X_tr\"]; y_tr = best_run[\"y_tr\"]\n",
    "X_ts = best_run[\"X_ts\"]; y_ts = best_run[\"y_ts\"]\n",
    "qml_best = best_run[\"qml\"]\n",
    "lr_best = best_run[\"lr\"]\n",
    "mlp_best = best_run[\"mlp\"]\n",
    "\n",
    "# Rango similar al del paper\n",
    "x_min, x_max = 0.0, 3.0\n",
    "y_min, y_max = 0.0, 3.0\n",
    "\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(x_min, x_max, 200),\n",
    "    np.linspace(y_min, y_max, 200)\n",
    ")\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "Z_qml = qml_best.predict(grid).reshape(xx.shape)\n",
    "Z_lr  = lr_best.predict(grid).reshape(xx.shape)\n",
    "Z_mlp = mlp_best.predict(grid).reshape(xx.shape)\n",
    "\n",
    "def plot_decision(ax, Z, title):\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3)\n",
    "    ax.scatter(X_tr[y_tr==0,0], X_tr[y_tr==0,1], c='red', marker='^', label='Class 0 (train)', alpha=0.6)\n",
    "    ax.scatter(X_tr[y_tr==1,0], X_tr[y_tr==1,1], c='blue', marker='o', label='Class 1 (train)', alpha=0.6)\n",
    "    ax.set_xlabel(r\"$\\sqrt{\\mathrm{variance} + \\mathrm{skewness}}$\")\n",
    "    ax.set_ylabel(\"Curtosis\")\n",
    "    ax.set_title(title)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4), sharex=True, sharey=True)\n",
    "plot_decision(axes[0], Z_qml, \"Qubit QML (ES λ=24, 60 gens)\")\n",
    "plot_decision(axes[1], Z_mlp, \"Multilayer Perceptron\")\n",
    "plot_decision(axes[2], Z_lr,  \"Logistic Regression\")\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ef95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7. Confusion matrix for best QML run ===\n",
    "from itertools import product\n",
    "\n",
    "y_pred_qml = qml_best.predict(X_ts)\n",
    "cm = confusion_matrix(y_ts, y_pred_qml)\n",
    "\n",
    "print(\"Confusion matrix (test set, best QML run):\")\n",
    "print(cm)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "im = ax.imshow(cm, cmap=\"Blues\")\n",
    "for i, j in product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "ax.set_xticklabels([\"Pred 0\", \"Pred 1\"])\n",
    "ax.set_yticklabels([\"True 0\", \"True 1\"])\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
